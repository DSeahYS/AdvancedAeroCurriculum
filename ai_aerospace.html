<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SpaceWiki | Autonomous Horizons</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Outfit:wght@300;400;600;700&family=Space+Mono:wght@400;700&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" href="styles.css">

    <!-- Three.js -->
    <script type="importmap">
        {
            "imports": {
                "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
                "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/"
            }
        }
    </script>
    <!-- MathJax -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>

    <canvas id="bg-canvas"></canvas>

    <nav class="sidebar">
        <a href="index.html" class="logo">
            <span>✦</span> SpaceWiki
        </a>

        <div class="nav-group">
            <div class="nav-header">Curriculum</div>
            <a href="undergrad.html" class="nav-link">Undergraduate</a>
            <a href="grad.html" class="nav-link">Graduate</a>
            <a href="phd.html" class="nav-link">PhD / Research</a>
        </div>

        <div class="nav-group">
            <div class="nav-header">Special Reports</div>
            <a href="ai_aerospace.html" class="nav-link">Autonomous Horizons (AI)</a>
        </div>
    </nav>

    <main class="main-content">
        <div class="content-wrapper">
            <h1>Autonomous Horizons</h1>
            <p class="hero-subtitle">The Operationalization of Artificial Intelligence in Aerospace and Astronautics
                (2024–2025)</p>

            <section id="introduction">
                <h2>1. Introduction: The Semantic Shift from Automation to Autonomy</h2>
                <p>The trajectory of aerospace engineering in the mid-2020s is defined not merely by incremental
                    improvements in propulsion or materials science, but by a fundamental architectural rupture in how
                    spacecraft perceive, reason, and act. For decades, the paradigm of spaceflight operations was
                    predicated on automation—the execution of deterministic, pre-scripted sequences triggered by time or
                    simple state thresholds. This model, while reliable for predictable environments, is proving
                    increasingly brittle in the face of the burgeoning complexity of the modern orbital and deep-space
                    domains. The 2024–2025 timeframe marks the definitive transition to autonomy, characterized by
                    systems capable of semantic understanding, stochastic decision-making, and adaptive learning in the
                    presence of high uncertainty.</p>
                <p>This shift is driven by two countervailing pressures: the "data deluge" generated by modern
                    hyperspectral and synthetic aperture radar (SAR) sensors, which far outstrips available downlink
                    bandwidth, and the "latency wall" inherent to deep space operations, which precludes
                    human-in-the-loop control for critical phases such as entry, descent, and landing (EDL). The
                    response from the engineering community has been the integration of "Edge AI"—bringing
                    high-performance inference directly to the sensor focal plane—and the adoption of learning-based
                    control policies that can generalize to unseen environments.</p>
            </section>

            <section id="computational-substrates">
                <h2>2. Computational Substrates: The Hardware-Software Convergence at the Edge</h2>
                <p>The deployment of artificial intelligence in the harsh environment of space is fundamentally a
                    problem of constraints. The size, weight, and power (SWaP) limitations of spacecraft, combined with
                    the destructive effects of ionizing radiation, render terrestrial AI accelerators (like commercial
                    GPUs) largely unsuitable for long-duration missions. The 2024–2025 period has witnessed a
                    renaissance in specialized computer architecture designed to bridge this gap, moving from
                    general-purpose processors to domain-specific neuromorphic and radiation-hardened architectures.</p>

                <div class="image-placeholder" id="img-neuromorphic">
                    <!-- Image will be injected here -->
                    <img src="artifacts/neuromorphic_chip.png" alt="Neuromorphic Chip Visualization"
                        class="content-image">
                </div>

                <h3>2.1 The Neuromorphic Paradigm: Bio-Inspired Efficiency</h3>
                <p>Neuromorphic computing represents a departure from the von Neumann bottleneck, where data must move
                    between memory and processing units, consuming energy with every transfer. Instead, neuromorphic
                    architectures colocate memory and computation, mimicking the synaptic structure of biological
                    brains. This architecture is event-driven; neurons only "fire" (consume power) when input signals
                    change, making it exceptionally efficient for the sparse data environments typical of space (e.g.,
                    star tracking, debris detection against a dark background).</p>

                <h3>2.1.1 Spiking Neural Networks (SNNs) and ExoSpikeNet</h3>
                <p>The software realization of this hardware paradigm is the Spiking Neural Network (SNN). Unlike
                    traditional Artificial Neural Networks (ANNs) that process continuous floating-point values, SNNs
                    communicate via discrete spikes in time. This temporal sparsity aligns perfectly with the physics of
                    event-based vision sensors. Research in 2025 has demonstrated that SNNs can achieve energy
                    efficiencies 100 to 1000 times greater than conventional processors for specific inference tasks.
                </p>
                <p>A prime exemplar of this capability is the ExoSpikeNet architecture, developed for the detection of
                    exoplanets via light curve analysis. The dynamics of these neurons are governed by the differential
                    equation:</p>
                <div class="math-block">
                    $$ \tau_m \frac{dV(t)}{dt} = -(V(t) - V_{rest}) + RI(t) $$
                </div>
                <p>where $\tau_m$ is the membrane time constant, $V(t)$ is the membrane potential, $V_{rest}$ is the
                    resting potential, and $I(t)$ is the synaptic input current. When $V(t)$ exceeds a threshold
                    $V_{th}$, the neuron fires a spike and resets. This mechanism allows the network to inherently
                    filter high-frequency noise while retaining the signal structure of the transit.</p>
            </section>

            <section id="gnc">
                <h2>3. Guidance, Navigation, and Control (GNC): The Algorithmic Revolution</h2>
                <p>If hardware provides the brain, Guidance, Navigation, and Control (GNC) algorithms provide the
                    specialized motor skills required for spaceflight. Historically, GNC has been the domain of control
                    theory—PID controllers, Kalman filters, and convex optimization. These methods are mathematically
                    provable but often brittle when facing unmodeled dynamics. The 2024–2025 period sees the rise of
                    Deep Reinforcement Learning (DRL) and Transformers as robust alternatives capable of handling the
                    non-linear complexities of planetary landing and orbital robotics.</p>

                <div class="image-placeholder" id="img-landing">
                    <!-- Image will be injected here -->
                    <img src="artifacts/lunar_landing.png" alt="Autonomous Lunar Landing" class="content-image">
                </div>

                <h3>3.1 Pinpoint Planetary Landing via Meta-Reinforcement Learning</h3>
                <p>Future exploration of the Moon (Artemis program) and Mars requires landing accuracies within meters
                    of a target, often in hazardous, unmapped terrain. Traditional gravity-turn guidance relies on
                    accurate state estimation and pre-loaded terrain maps, which may not exist.</p>
                <p>Meta-Reinforcement Learning (Meta-RL) has emerged as a powerful solution to this problem. In this
                    framework, an agent is not trained to master a single landing site, but rather trained on a
                    distribution of environments (different gravity, terrain roughness, lighting conditions). This
                    allows the agent to learn a "meta-policy" that can quickly adapt to the specific conditions of the
                    actual landing site with minimal real-time data.</p>

                <h3>3.3 Transformer-Based Trajectory Optimization</h3>
                <p>Perhaps the most radical innovation in GNC is the application of Transformers—the architecture behind
                    ChatGPT—to trajectory optimization. Traditionally, complex missions are broken into distinct phases
                    (launch, coast, orbit insertion, landing), each with a separate controller. This segmentation
                    creates "handover" risks.</p>
                <p>A 2025 study introduces a Transformer-based Reinforcement Learning method for multi-phase
                    optimization. In this paradigm, the spacecraft's state history is treated as a sequence of tokens,
                    similar to words in a sentence. The Transformer's self-attention mechanism allows the agent to
                    maintain "coherent memory" across long time horizons, effectively learning a single, unified control
                    policy that can transition seamlessly between different dynamical regimes.</p>
            </section>

            <section id="swarm">
                <h2>4. Swarm Intelligence and Mega-Constellation Management</h2>
                <p>The low Earth orbit (LEO) environment has undergone a phase transition. With the deployment of
                    mega-constellations numbering in the thousands (Starlink, Kuiper, Guowang), the topology of orbital
                    infrastructure has shifted from sparse and static to dense and dynamic. Centralized ground control,
                    the standard for sixty years, is now mathematically intractable due to the $O(N^2)$ complexity of
                    interactions and the latency of ground links. The solution is decentralized Swarm Intelligence.</p>

                <div class="image-placeholder" id="img-swarm">
                    <!-- Image will be injected here -->
                    <img src="artifacts/satellite_swarm.png" alt="Satellite Swarm Network" class="content-image">
                </div>

                <h3>4.1 Distributed Collision Avoidance: The OrbitZoo Benchmark</h3>
                <p>As orbital density increases, collision avoidance becomes a continuous background process rather than
                    a rare emergency. To train autonomous agents for this task, the research community has standardized
                    on OrbitZoo, a high-fidelity Multi-Agent Reinforcement Learning (MARL) environment. Unlike previous
                    simplified simulators, OrbitZoo is validated against real Starlink ephemeris data, achieving a Mean
                    Absolute Percentage Error (MAPE) of just 0.16% in trajectory propagation.</p>
            </section>

            <section id="astrophysics">
                <h2>6. AI in Astrophysics: The Scientific Force Multiplier</h2>
                <p>While engineering operations focus on survival and efficiency, AI in astrophysics is focused on
                    discovery. The volume of data from missions like TESS, Kepler, and the upcoming PLATO is so vast
                    that "human-in-the-loop" discovery is becoming a bottleneck.</p>

                <div class="image-placeholder" id="img-blackhole">
                    <!-- Image will be injected here -->
                    <img src="artifacts/black_hole_ai.png" alt="Black Hole AI Analysis" class="content-image">
                </div>

                <h3>6.1 Graph Neural Networks for Exoplanet Detection</h3>
                <p>For years, 1D Convolutional Neural Networks (CNNs) were the standard for analyzing light curves
                    (brightness over time). However, 2025 research indicates that Graph Neural Networks (GNNs) offer a
                    superior representation. By modeling the light curve points as nodes in a graph, GNNs can capture
                    non-linear relationships and long-term dependencies that convolution windows might miss.</p>
            </section>

            <section id="verification">
                <h2>7. The Verification Gap: Safety, Standards, and Ethics</h2>
                <p>The capabilities described above paint a picture of a highly autonomous future. However, the "black
                    box" nature of deep neural networks presents a fundamental barrier to deployment in safety-critical
                    systems. In aerospace, "probabilistic correctness" (e.g., 99% accuracy) is insufficient; systems
                    must be "provably correct" to meet certification standards.</p>
                <p>To bridge this gap, NASA and other agencies are heavily investing in Formal Verification. The goal is
                    to mathematically prove that a neural network's output will always fall within safe bounds for a
                    given input space. Prophecy, a tool developed at NASA Ames, infers formal properties of feed-forward
                    neural networks. It works by analyzing the activation patterns of neurons in hidden layers. It
                    extracts rules (preconditions) that imply a certain output.</p>
            </section>

            </section>

            <section id="ai-curriculum">
                <h2>8. AI & Autonomous Horizons Curriculum</h2>
                <p>Focus: The intersection of Deep Learning and Spaceflight.</p>

                <h3>Stanford University</h3>
                <ul>
                    <li><strong>AA 228 Decision Making under Uncertainty</strong>: Taught by Mykel Kochenderfer. Covers
                        Markov Decision Processes (MDPs), Reinforcement Learning (POMDPs), and Bayesian Networks for
                        collision avoidance (ACAS X).</li>
                    <li><strong>CS 229 Machine Learning (Aerospace Applications)</strong>: General ML with projects
                        often focusing on Satellite Image Segmentation or Rocket Landing via RL.</li>
                </ul>

                <h3>MIT</h3>
                <ul>
                    <li><strong>16.410/16.413 Principles of Autonomy and Decision Making</strong>: Path planning (A*,
                        RRT), constraint satisfaction, and logic-based AI for Mars rovers.</li>
                </ul>
            </section>

            <section id="code-the-future">
                <h2>9. Code the Future</h2>
                <p>Want to build the collision avoidance systems described in Section 4? Check out the curriculum for
                    <strong>Stanford AA 228</strong> and explore the code here:</p>
                <ul>
                    <li><a href="https://github.com/kenoung/aa228" target="_blank">kenoung/aa228</a>: Complete
                        Julia/Python implementations for <strong>Value Iteration</strong>, <strong>Q-Learning</strong>,
                        and <strong>Dynamic Programming</strong>.</li>
                    <li><a href="https://github.com/rbalexan/aa-228" target="_blank">rbalexan/aa-228</a>: Reinforcement
                        Learning implementations for dynamic systems.</li>
                    <li><strong>Aerospace-AI-optimization</strong>: Search for "Multi-Agent Reinforcement Learning
                        (MARL) for Satellites" to find code relevant to Swarm Intelligence.</li>
                </ul>
            </section>

        </div>
    </main>

    <script type="module" src="main.js"></script>
</body>

</html>